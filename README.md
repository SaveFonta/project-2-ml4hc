# ðŸ§  Project 2 â€“ Interpretable and Explainable Machine Learning for Healthcare (ML4HC)

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

This project explores interpretable and explainable machine learning methods in healthcare.  
It is structured around two main applications:

1. **Heart failure prediction** from tabular clinical data  
2. **Pneumonia detection** from chest X-ray images  

The goal is to understand how both **model design** and **post-hoc explainability techniques** can provide insights into predictions made by machine learning models â€” ensuring that models are not only accurate but also transparent and trustworthy for medical applications.

---

## ðŸ“¦ Project Organization

```

â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from Kaggle or third-party sources
â”‚   â”œâ”€â”€ interim        <- Intermediate transformed data
â”‚   â”œâ”€â”€ processed      <- Cleaned and ready-to-use data for modeling
â”‚   â””â”€â”€ raw            <- Original, immutable data dumps
â”‚
â”œâ”€â”€ docs               <- Documentation and project handouts
â”‚
â”œâ”€â”€ models             <- Trained models, predictions, and evaluation summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks (numbered and descriptive)
â”‚   â”œâ”€â”€ part1.ipynb                <- Heart Failure Prediction (Tabular)
â”‚   â””â”€â”€ part2/1_fb_part2.ipynb     <- Pneumonia Detection (Images)
â”‚
â”œâ”€â”€ proj2/              <- Main source code
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ config.py               <- Configuration variables and constants
â”‚   â”œâ”€â”€ dataset.py              <- Dataset download and setup logic
â”‚   â”œâ”€â”€ features.py             <- Feature engineering utilities
â”‚   â”œâ”€â”€ modeling/
â”‚   â”‚   â”œâ”€â”€ train.py            <- Model training pipeline
â”‚   â”‚   â”œâ”€â”€ predict.py          <- Inference and evaluation scripts
â”‚   â”‚   â””â”€â”€ **init**.py
â”‚   â”œâ”€â”€ part2/
â”‚   â”‚   â”œâ”€â”€ dataloader.py       <- Dataset and DataLoader for X-ray images
â”‚   â”‚   â””â”€â”€ training.py         <- CNN training and evaluation loops
â”‚   â””â”€â”€ plots.py                <- Visualization and interpretability plots
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/                <- Generated plots and saliency maps
â”‚   â””â”€â”€ analysis/               <- Reports and summaries
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.cfg
â””â”€â”€ pyproject.toml

````

---

## âš™ï¸ Setup

It is **strongly recommended** to install dependencies in a virtual environment to ensure reproducibility.

```bash
# Create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate        # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
````

---

## ðŸ”§ Dataset Setup & Configuration

The project requires datasets from **Kaggle** for both parts.
Before downloading, create a `.env` file in the project root (same level as `proj2/`) and set your Kaggle API credentials:

```bash
KAGGLE_USERNAME=your_username
KAGGLE_KEY=your_api_key
KAGGLEHUB_CACHE=data/external/
```

You can use the provided `.env.example` as a template.
More information: [Kaggle API documentation](https://www.kaggle.com/docs/api)

### Dataset Download

The dataset setup script automatically:

* Loads credentials from `.env`
* Uses `kagglehub` to download datasets
* Caches files in `KAGGLEHUB_CACHE`
* Checks for local copies before re-downloading

Managed datasets:

* `data/external/datasets/fedesoriano` â†’ *Heart Failure Prediction*
* `data/external/datasets/paultimothymooney` â†’ *Chest X-Ray Pneumonia*

To download the datasets:

```bash
python -m proj2.dataset
```

Or, use the provided VSCode launch configuration for convenience.
This ensures all team members share a consistent, reproducible environment.

---

## ðŸš€ How to Run the Project

The project is divided into two main parts, each with separate datasets, models, and explainability methods.

---

### ðŸ«€ Part 1 â€“ Heart Failure Prediction (Tabular Data)

This part focuses on **interpretable models** for tabular clinical data using the [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction).

1. **Exploratory Data Analysis (EDA)**

   * Inspect feature distributions, handle missing values and outliers, and identify class imbalance.

2. **Logistic Lasso Regression**

   * Train an L1-regularized logistic model to determine key features.
   * Visualize feature importances and discuss interpretability.
   * Evaluate using **F1-score** and **Balanced Accuracy**.

3. **Multi-Layer Perceptron (MLP) + SHAP**

   * Train a simple MLP classifier.
   * Use **SHAP** values to explain individual predictions and global feature importance.
   * Compare feature attributions with Lasso Regression results.

4. **Neural Additive Models (NAMs)**

   * Implement and train a **NAM** for interpretable nonlinear modeling.
   * Visualize feature-wise contributions and compare against logistic and MLP models.

ðŸ““ Notebook:
`notebooks/part1.ipynb`

---

### ðŸ©» Part 2 â€“ Pneumonia Detection (Chest X-Ray Images)

This part focuses on **explainable deep learning** using CNNs trained on the [Chest X-Ray Pneumonia Dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia).

1. **Data Exploration & Preprocessing**

   * Visualize healthy vs. pneumonia samples.
   * Discuss potential biases (e.g., scanner artifacts).
   * Prepare train/test splits and data augmentations.

2. **CNN Classifier**

   * Train a convolutional neural network for binary classification.
   * Evaluate test performance and report accuracy, precision, recall, and F1-score.

3. **Post-hoc Explainability**

   * **Integrated Gradients:**
     Compute pixel attribution maps highlighting influential image regions.
   * **Grad-CAM:**
     Visualize class-discriminative heatmaps and compare consistency with Integrated Gradients.
   * **Data Randomization Test:**
     Assess the reliability of attribution methods by randomizing training labels and comparing maps.

ðŸ““ Notebook:
`notebooks/part2/1_fb_part2.ipynb`

---

## ðŸ§© Recommended VSCode Extension

Install [**Colorful Comments**](https://marketplace.visualstudio.com/items?itemName=ParthR2031.colorful-comments) for an enhanced development experience.
It highlights important comment keywords, helping you quickly navigate TODOs and explanations.

---

## ðŸ§  Key Concepts Explored

* **Interpretability vs. Explainability** in ML
* **Feature attribution** (Lasso, SHAP, NAMs)
* **Post-hoc explanation methods** (Integrated Gradients, Grad-CAM)
* **Sanity Checks** for interpretability reliability
* **Model transparency** and trust in healthcare AI

---


## ðŸ“œ License

Distributed under an open-source license (see `LICENSE`).

---
